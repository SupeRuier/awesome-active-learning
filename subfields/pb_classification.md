Papers:
- Binary non-batch classification: 
  1. [Heterogeneous uncertainty sampling for supervised learning [1994, ICML]](https://www.sciencedirect.com/science/article/pii/B978155860335650026X): Most basic **Uncertainty** strategy. Could be used with probabilistic classifiers. (1071 citations)
  2. [Support Vector Machine Active Learning with Applications to Text Classification [2001, JMLR]](http://www.jmlr.org/papers/v2/tong01a.html): Version space reduction with SVM. （2643 citations）
  3. [Query by committee [1992, COLT]](https://dl.acm.org/doi/abs/10.1145/130385.130417): **QBC**. The idea is to build multiple classifiers on the current labeled data by using the Gibbs algorithm. The selection is basing on the disagreement of classifiers. (1466 citations)
  4. [Query learning strategies using boosting and bagging [1998, ICML]](https://www.researchgate.net/profile/Naoki_Abe2/publication/221345332_Query_Learning_Strategies_Using_Boosting_and_Bagging/links/5441464b0cf2e6f0c0f60abf.pdf): Avoid Gibbs algorithm in QBC. Ensemble learning with diversity query.  (433 citations)
  5. [Active learning using pre-clustering [2004, ICML]](https://dl.acm.org/doi/abs/10.1145/1015330.1015349): (483 citations)
  6. [Diverse ensembles for active learning [ICML, 2004]](https://dl.acm.org/doi/10.1145/1015330.1015385): Previous QBC are hard to make classifiers very different from each other. This method use DECORATE to build classifiers. C4.5 as base learner. Outperform 4. Select the instance with the highest JS divergence. (339 citations)(Delete)
  7. [Combining active learning and semisupervised learning using Gaussian fields and harmonic functions [2003, ICML]](http://mlg.eng.cam.ac.uk/zoubin/papers/zglactive.pdf): Greedily select queries from the unlabeled data to minimize the estimated expected classification error. GRF as basic model. This is also the most computationally expensive query framework since it needs to iterate over the whole unlabeled pool. (517 citations)
  8. [Active learning with Gaussian Processes for object categorization [2007, ICCV]](https://ieeexplore.ieee.org/abstract/document/4408844): Consider both the distance from the boundary as well as the variance in selecting the points; this is only possible due to the availability of the predictive distribution in GP regression. A signiﬁcant boost in classiﬁcation performance is possible, especially when the amount of training data for a category is ultimately very small.(303 citations)
  9. [Hierarchical Sampling for Active Learning [2008, ICML]](https://dl.acm.org/doi/pdf/10.1145/1390156.1390183): Take into account both the uncertainty and the representativeness. The performance heavily depends on the quality of clustering results. (388 citations)
  10. [An analysis of active learning strategies for sequence labeling tasks [2008, CEMNL]](https://www.aclweb.org/anthology/D08-1112.pdf): Information density framework. The main idea is that informative instances should not only be those which are uncertain, but also those which are “representative” of the underlying distribution (i.e., inhabit dense regions of the input space).(659 citations)
  11. [Active Learning by Querying Informative and Representative Examples [2010, NIPS]](http://papers.nips.cc/paper/4176-active-learning-by-querying-informative-and-representative-examples): **QUIRE**. Optimization based. Not only consider the loss in the labeled data (uncertainty) but also consider the loss in the unlabeled data (representations, correct labels would leads small value of overall evaluation function.). This methods is very computationally expensive. (370 citations)
  12. [Bayesian active learning for classification and preference learning [2011, Arxiv]](https://arxiv.xilesou.top/abs/1112.5745): **BALD**. Seek the x for which the parameters under the posterior disagree about the outcome the most. (149 citations)
  13. [RALF: A Reinforced Active Learning Formulation for Object Class Recognition [2012, CVPR]](https://ieeexplore.ieee.org/abstract/document/6248108/): **RALF**. A time-varying combination of exploration and exploitation sampling criteria. (59 citations)
  14. [Active learning by learning [2015, AAAI]](https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewPaper/9636): **ALBL**. A single human-designed philosophy is unlikely to work on all scenarios. Given an appropriate choice for the multi-armed bandit learner, take the importance-weighted-accuracy as reward function (an unbiased estimator for the test accuracy). It is possible to estimate the performance of different strategies on the fly. SVM as underlying classifier.(41 citations)
  15. [Exploring Representativeness and Informativeness for Active Learning [2017, IEEE TRANSACTIONS ON CYBERNETICS]](https://ieeexplore.ieee.xilesou.top/abstract/document/7329991): Optimization based. The representativeness is measured by fully investigating the triple similarities that include the similarities between a query sample and the unlabeled set, between a query sample and the labeled set, and between any two candidate query samples. For representativeness, our goal is also to ﬁnd the sample that makes the distribution discrepancy of unlabeled data and labeled data small. For informativeness, use BvSB. (85 citations)
  16. [Learning active learning from data [2017, NIPS]](http://papers.nips.cc/paper/7010-learning-active-learning-from-data): **LAL**. Train a random forest regressor that predicts the expected error reduction for a candidate sample in a particular learning state. Previous works they cannot go beyond combining pre-existing hand-designed heuristics. Random forest as basic classifiers. (Not clear how to get test classiﬁcation loss l. It is not explained in both the paper and the code.)(73 citations)
  17. [Learning How to Actively Learn: A Deep Imitation Learning Approach [2018, ACL]](https://www.aclweb.org/anthology/P18-1174.pdf): Learn an AL policy using imitation learning, mapping situations to most informative query datapoints. (8 citations)

- Binary batch classification:
  1. [Incorporating diversity in active learning with support vector machines [2003, ICML]](https://www.aaai.org/Papers/ICML/2003/ICML03-011.pdf): Take the diversity of the selected instances into account, in addition to individual informativeness. The diversity considers the angles between the induced hyperplanes(471)
  2. [Representative sampling for text classiﬁcation using support vector machines [2003, ECIR]](https://link.springer.xilesou.top/chapter/10.1007/3-540-36618-0_28): Select the cluster centers of the instances lying within the margin of a support vector machine.: Propose a representative sampling approach that selects the cluster centers of the instances lying within the margin of a support vector machine. (220)
  3. Large-scale text categorization by batch mode active learning [2006, ICWWW]: (250 citations)
  4. [Batch mode active learning and its application to medical image classification [2006, ICML]](https://dlacm.xilesou.top/doi/abs/10.1145/1143844.1143897): An approach that uses Fisher information matrix for instance selection. Use logistic regression. Efficiently identify the subset of unlabeled examples that can result in the largest reduction in the Fisher information based on the property of submodular functions. (367 citations)
  5. [Discriminative batch mode active learning [2008, NIPS]](http://papers.nips.cc/paper/3295-discriminative-batch-mode-active-learning): Optimization based. Formulate batch mode active learning as an optimization problem that aims to learn a good classiﬁer directly. Our optimization selects the best set of unlabeled instances and their labels to produce a classifier that attains maximum likelihood on labels of the labeled instances while attaining minimum uncertainty on labels of the unlabeled instances. (248 citations)
  6. [Semisupervised SVM batch mode active learning with applications to image retrieval [2009, TOIS]](https://dlacm.xilesou.top/doi/abs/10.1145/1508850.1508854): Optimization based. Provide the min-max view of active learning. Then directly select a batch of instance by optimization. (310 citations)
  7. Active instance sampling via matrix partition [2010, NIPS]: Maximizing a natural mutual information criterion between the labeled and unlabeled instances. No comparison with others.(69 citations)
  8. [Querying discriminative and representative samples for batch mode active learning [2015, TKDD]](https://dlacm.xilesou.top): Optimization based. **BMDR**. query the most informative samples while preserving the source distribution as much as possible, thus identifying the most uncertain and representative queries. Try to minimize the difference between two distributions (maximum mean discrepancy between iid. samples from the dataset and the actively selected samples). **Also extend to multi-class AL.** (82 citations)
  9. [Active Learning for Convolutional Neural Networks: A Core-Set Approach [2018, ICLR]](https://arxiv.xilesou.top/abs/1708.00489): **Core-set**. Optimization based. Use a heuristic to first filter the pool based on uncertainty and then choose point to label using diversity. Try to find a set of points to query labels (s1) such that when we learn a model, the performance of the model on the labelled subset and that on the whole dataset will be as close as possible.(128 citations)
  10. [BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning [2019, NIPS]](http://papers.nips.cc/paper/8925-batchbald-efficient-and-diverse-batch-acquisition-for-deep-bayesian-active-learning): Jointly score points by estimating the mutual information between a joint of multiple data points and the model parameters. BALD overestimates the joint mutual information. BatchBALD, however, takes the overlap between variables into account and will strive to acquire a better cover of ω.(5 citations)

- Multi-class non-batch classification:
  1. [Multi-class Ensemble-Based Active Learning [2006, ECML]](https://link.springer.com/chapter/10.1007/11871842_68): Extract the most valuable samples by margin-based disagreement, uncertainty, sampling-based disagreement, or specific disagreement. C4.5 as base learner. (52 citations)
  2. [Multi-Class Active Learning for Image Classification [CVPR, 2009]](https://ieeexplore.ieee.org/abstract/document/5206627): A comparison of **BvSB** and Entropy for active multi-classification. They use one-vs-one SVM. **Well accepted solution for multi-class classification.** (Very simple paper, just a comparison, nothing else) (338 citations)
  3. [Scalable Active Learning for Multiclass Image Classification [TPAMI, 2012]](https://ieeexplore.ieee.org/abstract/document/6127880/): Convert an active multi-class classification problem into a series active binary classification problem. One-vs-one SVM. Start with small seed sets, and allow dynamic addition of new classes. Oracle answer if the query selection match the class of the other selected image. (104 citations)
  4. [An active learning-based SVM multi-class classification model [2015, Pattern Recognition]](https://www.sciencedirect.com/science/article/pii/S003132031400497X): Use ove-vs-rest SVM, and select from the three types of unclear region (CBA, CCA, CNA). Allow the addition of new classes. (65 citations)

- Multi-class batch classification:
  1. [A batch-mode active learning technique based on multiple uncertainty for SVM classifier [2011, Geoscience and Remote Sensing Letters]](https://ieeexplore.ieee.org/abstract/document/6092438/): Batch-mode SVM-based method. Not only consider the smallest distances to the decision hyperplanes but also take into account the distances to other hyperplanes. Use kernel k-means to keep the diversity of the query batch. (43 citations)
  2. [Querying discriminative and representative samples for batch mode active learning [2015, TKDD]](https://dlacm.xilesou.top)


